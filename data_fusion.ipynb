{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install numpy \n",
    "# install the above packages if it is not installed in your environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_Data.csv')\n",
    "# inorder to read data by timestamp sequentially, I sort and group data by the 'timestamp_id'\n",
    "sorted_data_ts = data.sort_values(by=\"timestamp_id\")\n",
    "grouped_data_ts = sorted_data.groupby('timestamp_id')\n",
    "# print(grouped_data_ts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FUNCTION TO FUSE AND SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fuse_sensor_data(grouped_data,filename,threshold=2.0):\n",
    "    header_written = False\n",
    "    for timestamp, group in grouped_data:\n",
    "        # print(timestamp,group)\n",
    "        coords = group[['x_position', 'y_position']].values\n",
    "        #DBSCAN clusteres based on distance by fitting x and y coordinates or positions\n",
    "        clustered_db = DBSCAN(eps=threshold_distance, min_samples=1, metric='euclidean').fit(coords)\n",
    "        labels = clustered_db.labels_\n",
    "        unique_labels = np.unique(labels)\n",
    "        fuse_data =[]\n",
    "        #processing the ids for the clusters\n",
    "        for label in unique_labels:\n",
    "            cluster_data = group[labels == label]\n",
    "            datetime_values = pd.to_datetime(cluster_data['timestamp_id']).view(np.int64)\n",
    "            avg_timestamp = pd.Timestamp(datetime_values.mean()).isoformat(timespec='milliseconds') + \"Z\"\n",
    "\n",
    "            # print(avg_timestamp)\n",
    "\n",
    "\n",
    "            known_unique_ids = cluster_data[cluster_data['unique_id'] != 0]['unique_id'].unique()\n",
    "            if len(known_unique_ids) > 0:\n",
    "                f_u_id = known_unique_ids[0]\n",
    "            else:\n",
    "                f_u_id = 0\n",
    "        \n",
    "            cluster_list = cluster_data[['x_position', 'y_position', 'sensor_id']].values.tolist()\n",
    "\n",
    "            fuse_data.append({\n",
    "                'f_timestamp': avg_timestamp,\n",
    "                'f_id': np.random.randint(1, 1000000), \n",
    "                'cluster_data': cluster_list,\n",
    "                'f_u_id': f_u_id\n",
    "            })\n",
    "        fuse_data_df = pd.DataFrame(fuse_data)\n",
    "        fuse_data_df.to_csv(filename, mode='a', header=(not header_written), index=False)\n",
    "        header_written = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_distance = 2.0 \n",
    "filename = 'fused_file.csv'\n",
    "fuse_sensor_data(grouped_data_ts,filename,threshold=threshold_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
